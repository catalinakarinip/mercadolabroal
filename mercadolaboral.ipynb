{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPkX8b/ybT/GIXU9C0yvhrU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/catalinakarinip/mercadolabroal/blob/main/mercadolaboral.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Script 1: Limpieza bases INE"
      ],
      "metadata": {
        "id": "Uc46ixsIkE-N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para actualizar las bases limpias se debe\n",
        "1. Subir las bbdd originales del INE\n",
        "2. Ver si la base de diccionario \"variables_por_base\" mantiene las columnas, y por tanto las abreviaturas corresponden\n",
        "3. Cambiar nombre del archivo al compatible con la base de diccionario\n",
        "\n",
        "El code se demora 1 min en crear todas las bases limpias!!\n"
      ],
      "metadata": {
        "id": "st4DOtEXyi38"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ================= 0. MONTAR DRIVE =====================================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ================= 1. LIBRERÍAS ========================================\n",
        "from pathlib import Path\n",
        "import pandas as pd, re\n",
        "import re\n",
        "\n",
        "# ================= 2. RUTAS ============================================\n",
        "ROOT = Path(\"/content/drive/MyDrive/Data/Mercado_Laboral/Biobio\")\n",
        "ORIG_DIR  = ROOT / \"Datos_ENE_originales\"\n",
        "CLEAN_DIR = ROOT / \"Datos_ENE_limpios\"\n",
        "CLEAN_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "MAP_FILE  = ROOT / \"resultados/variables_por_base.xlsx\"\n",
        "MAP_SHEET = 0\n",
        "\n",
        "# ================= 3. DICCIONARIO DE ABREVIATURAS =====================\n",
        "def load_abbreviations() -> dict:\n",
        "    df_map = (\n",
        "        pd.read_excel(MAP_FILE, sheet_name=MAP_SHEET, usecols=\"A:C\")\n",
        "        .rename(columns=str.lower)\n",
        "        .dropna()\n",
        "    )\n",
        "    df_map[\"base\"] = (\n",
        "        df_map[\"base\"]\n",
        "        .str.strip()\n",
        "        .str.replace(\".xlsx\", \"\", regex=False)\n",
        "        .str.lower()\n",
        "    )\n",
        "    df_map[\"var_original\"] = df_map[\"var_original\"].str.strip()\n",
        "    df_map[\"abreviatura\"] = df_map[\"abreviatura\"].str.strip()\n",
        "    return {(r.base, r.var_original): r.abreviatura for r in df_map.itertuples()}\n",
        "\n",
        "# ================= 4. HOJAS A CONSERVAR ================================\n",
        "ID_VARS = [\"Año\", \"Trimestre\"]\n",
        "HOJAS_OBJETIVO = {\n",
        "    \"AS\",\n",
        "    \"AP\",\n",
        "    \"TA\",\n",
        "    \"AN\",\n",
        "    \"AT\",\n",
        "    \"CO\",\n",
        "    \"VA\",\n",
        "    \"RM\",\n",
        "    \"LI\",\n",
        "    \"ML\",\n",
        "    \"NB\",\n",
        "    \"BI\",\n",
        "    \"AR\",\n",
        "    \"LR\",\n",
        "    \"LL\",\n",
        "    \"AI\",\n",
        "    \"MA\",\n",
        "}\n",
        "\n",
        "# ================= 5. CONVERSIÓN NÚMEROS LATINOS =======================\n",
        "import re\n",
        "def texto_a_numero(valor):\n",
        "    if pd.isna(valor):\n",
        "        return None\n",
        "    texto = str(valor)\n",
        "    if re.match(r\"^\\d{1,3}(\\.\\d{3})*(,\\d+)?$\", texto):\n",
        "        texto = texto.replace(\".\", \"\").replace(\",\", \".\")\n",
        "    else:\n",
        "        texto = texto.replace(\",\", \".\")\n",
        "    try:\n",
        "        return float(texto)\n",
        "    except ValueError:\n",
        "        return None\n",
        "\n",
        "# ================= 6. LIMPIADOR DE HOJAS ===============================\n",
        "def limpiar_hoja(df: pd.DataFrame, base_alias: str, abbr: dict) -> pd.DataFrame:\n",
        "    df = df.copy()\n",
        "    df.columns = df.columns.str.strip()\n",
        "    columnas_a_borrar = []\n",
        "    renombres = {}\n",
        "    columnas = list(df.columns)\n",
        "\n",
        "    for i, col in enumerate(columnas):\n",
        "        if col in ID_VARS or \"Unnamed\" not in col:\n",
        "            continue\n",
        "        anterior = columnas[i - 1].strip() if i > 0 else \"\"\n",
        "        if anterior in ID_VARS or not anterior:\n",
        "            columnas_a_borrar.append(col)\n",
        "            continue\n",
        "        alias = abbr.get((base_alias, anterior))\n",
        "        if alias:\n",
        "            renombres[col] = f\"{alias}_{base_alias}\"\n",
        "        else:\n",
        "            columnas_a_borrar.append(col)\n",
        "\n",
        "    df = df.drop(columns=columnas_a_borrar, errors=\"ignore\").rename(columns=renombres)\n",
        "    df = df[df[ID_VARS[0]].notna() | df[ID_VARS[1]].notna()].reset_index(drop=True)\n",
        "\n",
        "    for col in renombres.values():\n",
        "        df[col] = df[col].apply(texto_a_numero)\n",
        "\n",
        "    return df[[*ID_VARS, *renombres.values()]]\n",
        "\n",
        "# ================= 7. PROCESAR ARCHIVOS =================================\n",
        "def procesar_archivos():\n",
        "    abbr = load_abbreviations()\n",
        "    for src in ORIG_DIR.glob(\"*.xlsx\"):\n",
        "        base_alias = src.stem.split(\"_\")[0].lower()\n",
        "        dest = CLEAN_DIR / f\"{base_alias}_limpia.xlsx\"\n",
        "        if dest.exists() and dest.stat().st_mtime >= src.stat().st_mtime:\n",
        "            print(f\"↻  Ya limpio: {dest.name}\")\n",
        "            continue\n",
        "        print(f\"→ Procesando {src.name} (base={base_alias})\")\n",
        "        xls = pd.ExcelFile(src)\n",
        "        with pd.ExcelWriter(dest, engine=\"openpyxl\") as xlw:\n",
        "            hojas_guardadas = 0\n",
        "            for hoja in xls.sheet_names:\n",
        "                if hoja not in HOJAS_OBJETIVO:\n",
        "                    continue\n",
        "                try:\n",
        "                    raw = xls.parse(hoja, header=5, dtype=str)\n",
        "                    limpio = limpiar_hoja(raw, base_alias, abbr)\n",
        "                    if not limpio.empty:\n",
        "                        limpio.to_excel(xlw, sheet_name=hoja, index=False)\n",
        "                        hojas_guardadas += 1\n",
        "                except Exception as e:\n",
        "                    print(f\"⚠️ Error en hoja '{hoja}': {e}\")\n",
        "            if hojas_guardadas == 0:\n",
        "                print(f\"⚠️ Ninguna hoja válida guardada en {src.name}\")\n",
        "    print(\"\\n✅ Limpieza completada. Archivos en:\", CLEAN_DIR)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    procesar_archivos()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysdcgLQAt61r",
        "outputId": "22f19b92-3f91-48c3-9cf3-51b4dd594ce9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "→ Procesando rama.xlsx (base=rama)\n",
            "→ Procesando informalidadtasas.xlsx (base=informalidadtasas)\n",
            "→ Procesando informalidadrama.xlsx (base=informalidadrama)\n",
            "→ Procesando informalidadgrupo.xlsx (base=informalidadgrupo)\n",
            "→ Procesando informalidadcategoria.xlsx (base=informalidadcategoria)\n",
            "→ Procesando indicadoresprincipales.xlsx (base=indicadoresprincipales)\n",
            "→ Procesando grupo.xlsx (base=grupo)\n",
            "→ Procesando complementarios.xlsx (base=complementarios)\n",
            "→ Procesando categoria.xlsx (base=categoria)\n",
            "\n",
            "✅ Limpieza completada. Archivos en: /content/drive/MyDrive/Data/Mercado_Laboral/Biobio/Datos_ENE_limpios\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Script 2: Panel de datos"
      ],
      "metadata": {
        "id": "Z9yXzopv8_2K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ================= 0. MONTAR DRIVE =====================================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ================= 1. LIBRERÍAS ========================================\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "# ================= 2. PARÁMETROS ======================================\n",
        "ROOT = Path(\"/content/drive/MyDrive/Data/Mercado_Laboral/Biobio\")\n",
        "CLEAN_DIR = ROOT / \"Datos_ENE_limpios\"\n",
        "TRIM_OK = {\"Ene - Mar\", \"Abr - Jun\", \"Jul - Sep\", \"Oct - Dic\"}\n",
        "MAPA = {\n",
        "    \"AP\": \"Arica y Parinacota\", \"TA\": \"Tarapacá\", \"AN\": \"Antofagasta\", \"AT\": \"Atacama\",\n",
        "    \"CO\": \"Coquimbo\", \"VA\": \"Valparaíso\", \"RM\": \"Región Metropolitana\", \"LI\": \"O’Higgins\",\n",
        "    \"ML\": \"Maule\", \"NB\": \"Ñuble\", \"BI\": \"Biobío\", \"AR\": \"Araucanía\", \"LR\": \"Los Ríos\",\n",
        "    \"LL\": \"Los Lagos\", \"AI\": \"Aysén\", \"MA\": \"Magallanes\", \"AS\": \"Nacional\"\n",
        "}\n",
        "REGIONES = set(MAPA.keys())\n",
        "\n",
        "# ================= 3. CONSTRUCCIÓN DEL PANEL ===========================\n",
        "paneles = []\n",
        "\n",
        "for archivo in CLEAN_DIR.glob(\"*_limpia.xlsx\"):\n",
        "    base = archivo.stem.replace(\"_limpia\", \"\")\n",
        "    xls = pd.ExcelFile(archivo)\n",
        "    for hoja in xls.sheet_names:\n",
        "        if hoja not in REGIONES:\n",
        "            continue\n",
        "        df = pd.read_excel(xls, sheet_name=hoja)\n",
        "        df = df[df[\"Trimestre\"].isin(TRIM_OK)].copy()\n",
        "        df[\"region_code\"] = hoja\n",
        "        df[\"region_name\"] = MAPA[hoja]\n",
        "        df[\"base\"] = base\n",
        "        paneles.append(df)\n",
        "\n",
        "# ================= 4. UNIFICAR Y GUARDAR ===============================\n",
        "panel = pd.concat(paneles, ignore_index=True)\n",
        "\n",
        "# OPCIONAL: guardar como archivo\n",
        "PANEL_FILE = ROOT / \"resultados\" / \"panel_ENE_unificado.xlsx\"\n",
        "panel.to_excel(PANEL_FILE, index=False)\n",
        "\n",
        "print(\"✅ Panel construido y guardado en:\", PANEL_FILE)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tS6MeK7R-38i",
        "outputId": "d02771f0-1704-4da6-f68f-3ac31d49f1b7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "✅ Panel construido y guardado en: /content/drive/MyDrive/Data/Mercado_Laboral/Biobio/resultados/panel_ENE_unificado.xlsx\n"
          ]
        }
      ]
    }
  ]
}